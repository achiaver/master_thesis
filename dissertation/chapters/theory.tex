EXPLICAR OS ELEMENTOS DE PROBABILIDADE COM OS QUAIS ESTAMOS LIDANDO:%
QUEM S\~{A}O AS VARI\'{A}VEIS ALEAT\'{O}RIAS E COMO VAMOS DOMIN\'{A}-LAS NO TEXTO,
COMENTAR QUE ESTAMOS TRATANDO COM VARI\'{A}VEIS DISCRETAS, COMO VAMOS IDENTIFICAR AS PROBABILIDADES,$\ldots$

EXPLICAR O QUE OS \'{I}NDICES REPResentam, e as vari\'{a}veis.

EXPLICAR OS TERMOS $\omega$ e $\phi$. $\omega$ \'{E} para os pesos, e $\phi$ para o bias de cada unidade.

EXPLICAR MINHA NOTA\c{C}\~{A}O sobre o sobre-escrito entre par\^{e}nteses!!!


In this chapter will expose the Boltzmann Machine theory. A few considerations regarding the notation used in this text is required before stepping forward into the main content.  


\section{Boltzmann Machines}

Boltzmann Machines (BM) are a type of stochastic neural networks (SNN) where the connections between units, which are described by $\omega$, are symmetrical, i.e., $\omega_{ij} = \omega_{ji}$ [HERTZ].
This kind of stochastic neural networks are capable of learning internal representation and to model an input distribution.
Boltzmann Machines were named after the Boltzmann distribution.
Due to its stochatics behaviour, the probability of the state of the system to be found in a certain configuration is given by previous mentioned distribution [HERTZ].
According to [MONTUFAR, 2018], BM can be seen as an extension of Hopfield networks to include hidden units.


Boltzamann Machines have visible and hidden units.
The visible units are linked to the external world and they correspond to the components of an observation. On the other hand, the hidden units do not have any connection outside of the network and model the dependencies between the components of the observations [FISCHER, 2012].
In BM, there is no connection restriction, this means that every unit, visible or hidden, can be connected to every other unit as in a complete graph, this pattern is not mandatory as some of the connections may not exists depending on the network layout.

Training Boltzmann Machines means finding the right connection between the units.

Boltzmann Machines (BM) are stochastics neural networks with symmetric connections, i.e., $\omega_{ij} = \omega_{ji}$.
Boltzmann Machines use the Boltzmann distribution to determine the probability of the state of the system of the network.
BM ressambles the Hopfield networks with the inclusion of hidden units.
Finding the right connections between the hidden units without knowing it from the training patterns what the hidden units represent is part of the solving the Boltzmann Machine problem.

Units $x_{i}$ in BM are split into two kinds: visible and hidden units.
The visible units have connection to the outside world and are the units that receive the data input.
On the other hand, the hidden units do not have any connection to the outside of the network and they are resposible to find the data relation from the input.
In a BM, the connections between units can be complete or not.
Regardless of how the connections are, every connection in a BM is symmetric.

BM are made of stochastics units $x_{i}$ which each of them can assume a binary value with a certain probabily as follows:
\begin{equation}
  x_{i} =
    \begin{cases}
      1 \; \text{with probability} \; g(h_{i}) \\
      0 \; \text{with probability} \; 1 - g(h_{i})
    \end{cases},
  \label{eq:eq1}
\end{equation}
where
\begin{equation}
  h_{i} = \sum_{j}\omega_{ij}x_{j},
  \label{eq:eq2}
\end{equation}
and
\begin{equation}
  g(h_{i}) = \frac{1}{1 + e^{-2 \beta h_{i}}}.
  \label{eq:eq3}
\end{equation}

Due to the symmetrical connections, there is an energy function give by
\begin{equation}
  H(\mathbf{x}) = - \sum_{i} \sum_{j} \omega_{ij}x_{i}x_{j} - \sum_{i} \phi_{i}x_{i},
  \label{eq:eq4}
\end{equation}
where $\mathbf{x} = (x_{1}, x_{2}, \dots, x_{n})$, and $n$ is equal to the number of units in the network, and the above energy function has minimum when there is a stable state characterised by
\begin{equation}
  x_{i} = sgn(h_{i}).
  \label{eq:eq5}
\end{equation}

The probability $P$ of finding the system in a given state $\mathbf{x}$ after the equilibrium is reached can be computed as follows:
\begin{equation}
  P(\mathbf{x}) = \frac{1}{Z} e^{-\beta H(\mathbf{x})},
  \label{eq:eq6}
\end{equation}
where
\begin{equation}
  Z = \sum_{\mathbf{x}'} e^{-\beta H(\mathbf{x}')}
  \label{eq:eq7}
\end{equation}
is the partition function.

The learning process of a Boltzmann Machine consists in ajusting the connections $\omega_{ij}$ in such a way that the state of the visible units have a particular desired probability distribution.

Let us identify the state of the visible units by an index $v$ and the state of the hidden units by an index $h$.
Considering a system which has N visible units and K hidden units, the whole system have $2^{N + K}$ possibilities of states in which it can be found.

The joint probability $P_{vh}$ is the probability of finding the visible and hidden units in the states $v$ and $h$, respectively.
This probabiblity measument is given by the Boltzmann distribution:
\begin{equation}
  P_{vh} = \frac{e^{-\beta H_{vh}}}{Z},
  \label{eq:eq8}
\end{equation}
where
\begin{equation}
  Z = \sum_{u} \sum_{k} e^{-\beta H_{uk}},
  \label{eq:eq9}
\end{equation}
and
\begin{equation}
  H_{vh} = - \sum_{i} \sum_{j} \omega_{ij} x^{(vh)}_{i} x^{(vh)}_{j} - \sum_{i} \phi_{i} x^{(vh)}_{i}.
  \label{eq:eq10}
\end{equation}

As metioned above, the problem a Boltzmann Machine is trying to solve is determining the connections $\omega_{ij}$ between units such that the visible units have a certain probability distribution.
In order to do that, we need to find the marginal probability of the state $v$ in which the visible units are found regardless of the state $h$ of the hidden units. The marginal probability $P_{v}$ is given by
\begin{equation}
  P_{v} = \sum_{h} P_{vh} = \sum_{h} \frac{e^{-\beta H_{vh}}}{Z}.
  \label{eq:marginal_prob}
\end{equation}

Although we know that $P_{v}$ is a function of the connections $\omega_{ij}$, and that this is the probability of finding the visible units in the state $v$. We want the states to have a certain probability $Q_{v}$, i.e., a desired probability.
This means that ideally we would like to match the empirical distribution of the data, even though we do not have access to the correct distribution, only to what the observed data has given us as an input to training the model.

One way to evaluate the difference between two probability distribution, for example, $P_{v}$ and $Q_{v}$, is using the Kullback-Leibler divergence, which can also be referred to relative entropy, $E$, which will be our cost function.
(EXPLICAR FUN\c{C}\~{A}O DE CUSTO e $D_{KL}$!!!).
\begin{equation}
  E = \sum_{v} Q_{v} \ln{\left(\frac{Q_{v}}{P_{v}}\right)}.
  \label{eq:DKL}
\end{equation}

The relative entropy $E$ has the property of always being equal or greater than zero.
It reaches zero only if $P_{v} = Q_{v}$, which means that we are able to retrieve the exactly probability distribution of the input data at the visible units.
\begin{equation}
  \begin{split}
    E & = \sum_{v} Q_{v} \ln{\left( \frac{Q_{v}}{P_{v}} \right)} \\
      & \geq \sum_{v} Q_{v} \left( 1 - \frac{P_{v}}{Q_{v}} \right) \\
      & = \sum_{v} \left( Q_{v} - P_{v} \right) \\
      & = \sum_{v} Q_{v} - \sum_{v} P_{v} = 1 - 1 \\
      & \Rightarrow E \geq 0.
  \end{split}
\end{equation}

From the gradient descent equation
\begin{equation}
  \Delta \omega_{ij} = -\eta \frac{\partial E}{\partial \omega_{ij}},
  \label{eq:gradient}
\end{equation}
where
\begin{equation}
  \begin{split}
    E & = \sum_{v} Q_{v} \ln{\left(\frac{Q_{v}}{P_{v}}\right)} \\
      & = \sum_{v} \left[ \ln{(Q_{v})} - \ln{(P_{v})} \right].
  \end{split}
  \label{eq:entropy1}
\end{equation}

In the following steps, we present the gradient descent derivation
\begin{equation}
  \begin{split}
    \Delta \omega_{ij} & = - \eta \frac{\partial E}{\partial \omega_{ij}} \\
                  & = - \eta \frac{\partial}{\partial \omega_{ij}} \left[ \sum_{v} Q_{v} \left( \ln{(Q_{v})} - \ln{(P_{v})} \right) \right] \\
                  & = \eta \frac{\partial}{\partial \omega_{ij}} \left[ \sum_{v} Q_{v} \ln{(P_{v})} \right] \\
                  & = \eta \sum_{v} Q_{v} \frac{\partial}{\partial \omega_{ij}} \left[ \ln{(P_{v})} \right] \\
                  \Rightarrow & \Delta \omega_{ij} = \eta \sum_{v} \frac{Q_{v}}{P_{v}} \frac{\partial P_{v}}{\partial \omega_{ij}}.
  \end{split}
  \label{eq:grad1}
\end{equation}

To continue with the computation of $\Delta \omega_{ij}$, we have to find the derivative of $\partial P_{v}/\partial \omega_{ij}$, from the marginal probability, equation~\ref{eq:marginal_prob},
\begin{equation}
  P_{v} = \frac{\sum_{h} e^{-\beta H_{vh}}}{\sum_{u} \sum_{k} e^{-\beta H_{u k}}},
  \label{eq:marginal_prob_expansion}
\end{equation}
thus the derivative of $P_{v}$ follows
\begin{equation}
  \begin{split}
    \frac{\partial P_{v}}{\partial \omega_{ij}} & = \frac{\partial}{\partial \omega_{ij}} \left[ \frac{\sum_{h} e^{-\beta H_{vh}}}{\sum_{u} \sum_{k} e^{-\beta H_{u k}}} \right] \\
    & = \frac{1}{\sum_{u} \sum_{k} e^{-\beta H_{u k}}} \sum_{h} (-\beta) e^{-\beta H_{vh}} \frac{\partial H_{vh}}{\partial \omega_{ij}} \\
    & - \sum_{h} e^{-\beta H_{vh}} \frac{1}{{\left( \sum_{u} \sum_{k} e^{-\beta H_{u k}} \right)}^{2}} \sum_{u} \sum_{k} e^{-\beta H_{u k}} (-\beta) \frac{\partial H_{u k}}{\partial \omega_{ij}}.
  \end{split}
  \label{eq:eq14}
\end{equation}

Following the equation~\ref{eq:eq14}, we need to compute the term $\partial H_{vh}/\partial \omega_{ij}$,
\begin{equation}
  \begin{split}
      \frac{\partial H_{vh}}{\partial \omega_{ij}} & = \frac{\partial}{\partial \omega_{ij}} \left[- \frac{1}{2} \sum_{m} \sum_{n} \omega_{mn} x^{(vh)}_{m} x^{(vh)}_{n} - \sum_{m} \phi_{mm} x^{(vh)}_{m} \right] \\
                                                   & = \frac{\partial}{\partial \omega_{ij}} \left[- \frac{1}{2} \sum_{m \neq i,j} \sum_{n \neq i,j} \omega_{mn} x^{(vh)}_{m} x^{(vh)}_{n} - \frac{1}{2} \omega_{ij} x^{(vh)}_{i} x^{(vh)}_{j} - \frac{1}{2} \omega_{ji} x^{(vh)}_{j} x^{(vh)}_{i} - \sum_{m} \phi_{m} x^{(vh)}_{m} \right],
  \end{split}
  \label{eq:eq15}
\end{equation}
as the connections between units are symmetric, i.e., $\omega_{ij} = \omega_{ji}$, then we can simplify equation~\ref{eq:eq15},
\begin{equation}
  \begin{split}
    \frac{\partial H_{vh}}{\partial \omega_{ij}} & = \frac{\partial}{\partial \omega_{ij}} \left[- \frac{1}{2} \sum_{m \neq i,j} \sum_{n \neq i,j} \omega_{mn} x^{(vh)}_{m} x^{(vh)}_{n} - \omega_{ij} x^{(vh)}_{i} x^{(vh)}_{j} - \sum_{m} \phi_{m} x^{(vh)}_{m} \right] \\
    & = \frac{\partial}{\partial \omega_{ij}} \left[- \frac{1}{2} \sum_{m \neq i,j} \sum_{n \neq i,j} \omega_{mn} x^{(vh)}_{m} x^{(vh)}_{n} \right] + \frac{\partial}{\partial \omega_{ij}} \left[- \omega_{ij} x^{(vh)}_{i} x^{(vh)}_{j} \right] + \frac{\partial}{\partial \omega_{ij}} \left[- \sum_{m} \phi_{m} x^{(vh)}_{m} \right] \\
    \Rightarrow & \frac{\partial H_{vh}}{\partial \omega_{ij}} = - x^{(vh)}_{i} x^{(vh)}_{j}.
  \end{split}
  \label{eq:eq16}
\end{equation}

Analagous to $\partial H_{vh}/\partial \omega_{ij}$, we have $H_{uk}$ derivative, which is
\begin{equation}
  \frac{\partial H_{uk}}{\partial \omega_{ij}} = - x^{(uk)}_{i} x^{(uk)}_{j}.
  \label{eq:eq17}
\end{equation}

Going back to equation~\ref{eq:eq14}, we can replace the derivatives of $H$, and solve the derivative of the marginal probability $P_{v}$,
\begin{equation}
  \begin{split}
    \frac{\partial P_{v}}{\partial \omega_{ij}} & = \frac{1}{Z} \sum_{h} e^{-\beta H_{vh}} (-\beta) (-x^{(vh)}_{i} x^{(vh)}_{j}) - \frac{1}{Z^{2}} \sum_{h} e^{-\beta H_{vh}} \sum_{u} \sum_{k} e^{-\beta H_{uk}} (-\beta) (-x^{(uk)}_{i} x^{(uk)}_{j}) \\
    & = \beta \left[ \sum_{h} \frac{e^{-\beta H_{vh}}}{Z} x^{(vh)}_{i} x^{(vh)}_{j} - \sum_{h} \frac{e^{-\beta H_{vh}}}{Z} \sum_{u} \sum_{k} \frac{e^{-\beta H_{uk}}}{Z} x^{(uk)}_{i} x^{(uk)}_{j}  \right] \\
    & = \beta \left[ \sum_{h} P_{vh} x^{(vh)}_{i} x^{(vh)}_{j} - P_{v} \sum_{u} \sum_{k} P_{uk} x^{(uk)}_{i} x^{(uk)}_{j} \right] \\
    \Rightarrow & \frac{\partial P_{v}}{\partial \omega_{ij}} = \beta \left[ \sum_{h} P_{vh} x^{(vh)}_{i} x^{(vh)}_{j} - P_{v} \langle x_{i} x_{j} \rangle  \right].
  \end{split}
  \label{eq:eq18}
\end{equation}

Given the derivative of $P_{v}$ in relation to $\omega_{ij}$, we can compute the learning term $\Delta \omega_{ij}$, from equation~\ref{eq:grad1},
\begin{equation}
  \begin{split}
    \Delta \omega_{ij} & = \eta \sum_{v} \frac{Q_{v}}{P_{v}} \beta \left[ \sum_{h} P_{vh} x^{(vh)}_{i} x^{(vh)}_{j} - P_{v} \langle x_{i} x_{j} \rangle \right]  \\
    & = \eta \beta \left[ \sum_{v} \sum_{h} \frac{Q_{v}}{P_{v}} P_{vh} x^{(vh)}_{i} x^{(vh)}_{j} - \sum_{v} \frac{Q_{v}}{P_{v}} P_{v} \langle x_{i} x_{j} \rangle \right] \\
    & = \eta \beta \left[ \sum_{v} \sum_{h} Q_{v} \frac{P_{vh}}{P_{v}} x^{(vh)}_{i} x^{(vh)}_{j} - \sum_{v} Q_{v} \langle x_{i} x_{j} \rangle \right] \\
    & = \eta \beta \left[ \sum_{v} \sum_{h} Q_{v} P_{h|v} x^{(vh)}_{i} x^{(vh)}_{j} - \langle x_{i} x_{j} \rangle \right].
  \end{split}
  \label{eq:learning_term2}
\end{equation}

In the above derivation, we have used the following relations,
\begin{equation}
  P_{h|v} = \frac{P_{vh}}{P_{v}},
  \label{eq:conditional_prob1}
\end{equation}
which is the conditional probability equation.
In our scenario this equation means that the probability distribution of the hidden units in state $h$ given the state $v$ of the visible units is the joint probability distribution of both states, $v$ and $h$, divided by the marginal probability distribution of the visible units in state $v$.

The second term in equation~\ref{eq:learning_term2}, is the average of units $i$ and $j$ over all combinations of states $v$ and $h$ of the system. 
In other words, we would have to compute all possible combination of states of visible and hidden units, $v$ and $h$, and then average over the specific units $i$ and $j$. 

The first term can be simplified by
\begin{equation}
  \sum_{v} Q_{v} \sum_{h} P_{h|v} x^{(vh)}_{i} x^{(vh)}_{j} = \sum_{v} Q_{v} \langle x_{i} x_{j} \rangle^{(v)} = \langle \langle x_{i} x_{j} \rangle^{(v)} \rangle.
  \label{eq:clamped_term}
\end{equation}

Then equation~\ref{eq:learning_term2} becomes
\begin{equation}
  \Delta \omega_{ij} = \eta \beta \left[ \langle \langle x_{i} x_{j} \rangle^{(v)} \rangle_{clamped} - \langle x_{i} x_{j} \rangle_{free} \right],
  \label{eq:learning_term3}
\end{equation}
it is important to notice that the subscripts \textit{clamped} means that we have to fix a certain $v$ state on the visible units otherwise the second term in the equation does not have a reference. 
On the other hand, the subscript \textit{free} identify the $\ldots$
