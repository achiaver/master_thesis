Grande Área: Ciências Exatas e da Terra
Área: Ciência da Computação
Sub Área: Matemática da Computação

Palavras Chave:  Inteligência Computacional, Reconhecimento de padrões, Redes Neuronais Profundas


Título: Inteligência Computacional Utilizando Redes Neuronais Profundas

Resumo:
========

Este projeto dá continuidade ao trabalho que a orientadora do aluno Artur Chiaperini Grover vem realizando, sobre modelos computacionais de sistemas complexos, com ênfase em modelos conexionistas inspirados no funcionamento da mente e do cérebro. Estendemos nossos modelos de substratos neuronais que descrevem processos mentais e cerebrais, implementando simulações ilustrativas. Medimos grandezas que refletem propriedades relevantes destas redes complexas, utilizando teorias da mecânica estatística. Este projeto tem ênfase no estudo e implementação de Redes Neuronais Profundas (RNPs), que têm sido utilizadas para resolver problemas de inteligência artificial, em áreas como: reconhecimento automático de fala (ou voz), reconhecimento e tratamento de imagens, processamento de linguagem natural, bioinformática, entre muitas outras.


Introdução:
============

Atualmente, a modelagem de sistemas complexos inteligentes se utiliza de dois paradigmas principais, normalmente denominados de Simbolismo e Conexionismo, como diretrizes básicas para atingir seus objetivos de criação de máquinas inteligentes e de compreensão da cognição humana. Estas duas abordagens partem de diferentes posições, advogando cada uma delas vantagens em relação à outra na reprodução da atividade inteligente. A abordagem simbólica tradicional argumenta que a manipulação algorítmica de sistemas simbólicos é um contexto adequado para a modelagem dos processos cognitivos. Por outro lado, os conexionistas restringem-se a arquiteturas inspiradas no cérebro e argumentam que essa abordagem tem o potencial para superar a rigidez dos sistemas simbólicos, modelando mais precisamente tarefas cognitivas que só podem ser resolvidas, no melhor caso, de modo aproximado. Anos de experimentação com ambos os paradigmas nos levam à conclusão de que a solução se encontra entre esses dois extremos, e que as abordagens devem ser integradas e unificadas. A fim de se estabelecer uma ligação adequada entre elas, muito ainda há de ser pesquisado. 

Se na década dos anos oitenta, a discussão sobre a inteligência se colocava nos pólos distintos dos simbolistas e dos conexionistas, atualmente, os conexionistas se encontram divididos pelos argumentos reducionistas dos estruturalistas. Para esta corrente estruturalista, o insucesso dos simbolistas se deveu ao fato de que seus modelos desprezavam a arquitetura cerebral e, portanto, o conexionismo deve continuar explorando mais profundamente os aspectos estruturais do órgão pensante.  Neste projeto, os aspectos conexionsta e estruturalista são abordados, respectivamente, através do uso do paradigma das redes neuronais artificiais e de modelos realistas do cérebro, dentro da área denominada de Neurociência Computacional. Através de nossos modelos, investigamos questões antigas da Inteligência Artificial referentes à compreensão de aspectos da computabilidade da mente humana.

Neste projeto seguiremos com o estudo e implementação de Redes Neuronais Profundas (RNPs), que têm sido utilizadas para resolver problemas de inteligência artificial, em áreas como: reconhecimento automático de fala (ou voz), reconhecimento e tratamento de imagens, processamento de linguagem natural, bioinformática, entre muitas outras.

Nossa experiência anterior, tanto no desenvolvimento de pesquisa na área de redes neuronais artificiais e processamento distribuído em geral e suas aplicações tecnológicas, quanto na busca de modelos realistas da biologia cerebral, nos permite com maturidade continuar seguindo a mesma direção de pesquisa multidisciplinar. 



Justificativas:
===============

Nos últimos anos, as RNPs têm sido usadas com muito sucesso em diversas tarefas de análise de dados. Em 2011, pela primeira vez, o uso de métodos de aprendizagem com RNPs permitiu o alcance de desempenho melhor que o de um ser humano em uma competição para resolver problemas de reconhecimento de padrões visuais. Estas técnicas estão sendo muito utilizadas para a solução
de diversos problemas de inteligência computacional.



Objetivos:
==========

Estudaremos o problema de reconhecimento de padrões em dados, com Redes Neuronais Profundas. 
Estaremos realizando experimentos com o ajuste paramétrico do modelo, em problemas de reconhecimento de padrões, como análise de imagens e processamento de linguagem natural. 



Metas:
======

- Estudo dos algoritmos que compõem a técnica de Redes Neuronais Profundas.
- Estudo de problemas que se beneficiem da utilização destas técnicas de RNPs.
- Realização de experimentos com o ajuste paramétrico do modelo, para obter
  bom desempenho em problemas de reconhecimento de padrões em dados.
- Publicação e divulgação dos resultados de nosso trabalho.



Método:
=======

Utilizaremos Redes Neuronais com técnicas de aprendizagem profunda para realizar análise de dados. As RNPs constituem uma classe de algoritmos de aprendizagem de máquina, que usam uma cascata de múltiplas camadas, com unidades de processamento não lineares, para a extração de características em um conjunto de dados. Cada camada sucessiva recebe o sinal de saída da camada anterior como sinal de entrada. Estas redes podem usar técnicas de aprendizagem supervisionadas ou não-supervisionadas. Podem aprender múltiplos níveis de representações que correspondem a diferentes níveis de abstração.



Resultados Esperados:
=====================

Esperamos obter resultados que representem avanços na compreensão do método de Redes Neuronais Profundas e de como realizar os ajustes paramétricos do modelo, para realizar reconhecimento automático de padrões em problemas, como tratamento de imagens e processamento de linguagem natural. 



Referências:
============

1. Goodfellow, I., Bengio, Y. and Courville, A.,  Deep Learning, MIT Press, 2016.
2. Hertz, J. A.,  Krogh, A. and Palmer, R. G., Introduction to the Theory of Neural 
   Computation, (Santa Fe Institute Studies in the Sciences of Complexity. Lecture 
   Notes, Vol. 1), 1991. 
3. Bengio, Y., LeCun, Y., Hinton, G., Deep Learning, Nature. 521 (7553): 436–444, 2015.
4. Schmidhuber, J. Deep Learning in Neural Networks: An Overview, Neural Networks. 61: 85–117, 
   2015.
5. Deng, L., Yu, D., Deep Learning: Methods and Applications, Foundations and Trends 
   in Signal Processing. 7 (3–4): 1–199, 2014.
6. Patel, A., Nguyen, T., Baraniuk, R., A Probabilistic Framework for Deep Learning, Advances in 
   Neural Information Processing Systems, 2016.



Cronograma:
===========

1. Revisão Bibliográfica. Ano 1, Meses 1 a 10
2. Análise e estudo da literatura. Ano 1, Meses 6 a 12; Ano 2, Meses 1 e 2
3. Desenvolvimento do tema central da pesquisa. Ano 1, Meses 6 a 12; Ano 2, Meses 1 a 10
4. Divulgação de Resultados. Ano 2, Meses 9 a 12
5. Defesa. Ano 2, Meses 11 e 12



